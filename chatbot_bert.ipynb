{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your existing JSON data\n",
    "with open('C:/Users/Ajmel/Desktop/Ai_c/try/Travel-Guidence-Chatbot/chatbot_backend/chatapi/utils/baale_mountain.json', encoding='utf-8') as file:\n",
    "    intents = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "texts = []\n",
    "labels = []\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        texts.append(pattern)\n",
    "        labels.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save label encoder\n",
    "np.save('bert_label_encoder.npy', label_encoder.classes_)\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize data\n",
    "tokenized_data = tokenizer(\n",
    "    texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors='tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Create TensorFlow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(tokenized_data),\n",
    "    encoded_labels\n",
    ")).shuffle(1000).batch(16)\n",
    "\n",
    "# Initialize model\n",
    "model = TFBertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=len(label_encoder.classes_)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 49s 2s/step - loss: 2.6127 - accuracy: 0.2353\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 10s 2s/step - loss: 2.5215 - accuracy: 0.3137\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 9s 2s/step - loss: 2.4221 - accuracy: 0.2941\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 9s 2s/step - loss: 2.3195 - accuracy: 0.4706\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 9s 2s/step - loss: 2.2725 - accuracy: 0.5098\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 9s 2s/step - loss: 2.1607 - accuracy: 0.5294\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 9s 2s/step - loss: 2.0900 - accuracy: 0.5686\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.9854 - accuracy: 0.6667\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.9038 - accuracy: 0.6275\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.8280 - accuracy: 0.7843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x204810c2660>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(3e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training complete - Model saved to 'bert_baale_model'\n"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "model.save_pretrained('bert_baale_model')\n",
    "tokenizer.save_pretrained('bert_baale_model')\n",
    "\n",
    "print(\"✅ Training complete - Model saved to 'bert_baale_model'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
